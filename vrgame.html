<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Manikandan</title>
	<meta name="description" content="Manikandan's Portfolio" />
	<meta name="keywords" content="Portfolio, Interaction Design, Tangible Interactions, UMSI, UX Design" />
	<meta name="author" content="Manikandan K V" />
	<!-- Favicons (created with http://realfavicongenerator.net/)-->
<link rel="apple-touch-icon" sizes="57x57" href="img/favs/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="img/favs/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="img/favs/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="img/favs/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="img/favs/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="img/favs/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="img/favs/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="img/favs/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="img/favs/apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="img/favs/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="img/favs/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="img/favs/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="img/favs/favicon-16x16.png">
<link rel="manifest" href="img/favs/manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="img/favs/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">
	<!-- Normalize -->
	<link rel="stylesheet" type="text/css" href="css/normalize.css">
	<!-- Bootstrap -->
	<link rel="stylesheet" type="text/css" href="css/bootstrap.css">
	<!-- Owl -->
	<link rel="stylesheet" type="text/css" href="css/owl.css">
	<!-- Animate.css -->
	<link rel="stylesheet" type="text/css" href="css/animate.css">
	<!-- Font Awesome -->
	<link rel="stylesheet" type="text/css" href="fonts/font-awesome-4.1.0/css/font-awesome.min.css">
	<!-- Elegant Icons -->
	<link rel="stylesheet" type="text/css" href="fonts/eleganticons/et-icons.css">
	<!-- Main style -->
	<link rel="stylesheet" type="text/css" href="css/Main.css">
	<!-- google font -->
	<link href="https://fonts.googleapis.com/css?family=Comfortaa:300,400,700|Josefin+Sans:100,100i,300,300i,400,400i,600,600i,700,700i" rel="stylesheet">




</head>

<body>
	<div class="preloader">
		<img src="img/loader.gif" alt="Preloader image">
	</div>
	<nav class="navbar">
		<div class="container">
			<!-- Brand and toggle get grouped for better mobile display -->
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
					<span class="sr-only">Toggle</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a href="../index.html" class="navbar-brand" ><img src="img/Logo_2.svg" width="60%" data-active-url="img/Logo_2.svg" alt=""></a>
			</div>
			<!-- Collect the nav links, forms, and other content for toggling -->
			<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
				<ul class="nav navbar-nav navbar-right main-nav">
					<li><a href="#Home">Home</a></li>
                    <li><a href="#Overview">Overview</a></li>
					<li><a href="#Research">Research</a></li>
                    <li><a href="#Implementation">Implementation</a></li>
                    <li><a href="#Interactions">Interactions</a></li>
					<li><a href="#Prototype">Prototype</a></li>
					<li><a href="#Future">Future Work</a></li>
                    <li><a href="http://manikandan-k-v.com/index.html">Back to Portfolio</a></li>
					<!-- <li><a href="#" data-toggle="modal" data-target="#modal1" class="btn btn-blue">Sign Up</a></li> -->
				</ul>
			</div>
			<!-- /.navbar-collapse -->
		</div>
		<!-- /.container-fluid -->
	</nav>
<br>
<br>
<br>
	<header id="Home">
		<div class="container vrheader">

			<div class="table">

				<div class="header-text ">
					<div class="row">

						<div class="col-md-12 text-center">
                            <h1 class="StyledStrong">VR Game Controller Design</h1>
                            <h4 class="typed Styled">Motion Capture/Tracking • IxD/UX Design • Virtual Reality</h4>
							<span class="typed-cursor">|</span>
						</div>

					</div>
					<br><br><br><br>
				</div>
			</div>

		</div>
	</header>
	<section id="Overview" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styled">Overview</h2><br><br><br>
                <h4 class="styledStrong text-justify">About the Project:</h4>
				<h4 class ="styled text-justify">This project explores the user experience of a virtual reality gameplay by incorporating natural interactions with the VR objects through visual motion capture techniques.<br><br></h4>
                <h4 class="styledStrong text-justify">Why is this important?</h4>
				<h4 class ="styled text-justify">Virtual Reality became mainstream when Oculus, Samsung and HTC introduced specialized hardware and head mounted devices to experience virtual reality. Google approached VR with a different perspective aiming to make VR accessible and easy to use for everyone. This resulted in the creation of the Google Cardboard. Google Cardboard provided a platform by which every smartphone can be its own VR hardware. This concept made Virtual Reality accessible to a wide range of people worldwide. Game designers made use of this expanding platform to create more engaging games for users. <br><br> However, in this pursuit one should not forget that VR game is completely different from the traitional gaming platform and hence the method of interactions need to be reconsidered as well. This is why most of the traditional controllers do not provide the expected gameplay experience since the interactions are not "natural".<br><br></h4>
			</div>
			
		</div>
		
	</section>

	<section id="Research" class="section section-padded">
		<div class="container">
			<div class="row text-center title">
				<h2 class="styled">Research</h2><br><br><br>
                <h4 class ="styled text-justify">For this project the feasibility of using Microsoft Kinect for visual motion capture and to incorporate it in the virtual world was explored.<br><br>
                    
                    1) The paper “Applied research of somatosensory game based on Kinect and Unity3D data integration technology” (Liu, J. G, 2014) explores the concept of integrating Kinect with Unity3D and addresses the issues of integrating Kinect V2.0 with Unity3D for gaming.<br><br>2) The article “To Develop the Virtual Physics Laboratory by Integrating Kinect with Gesture Classification Algorithm” (Y. Z. Hsieh et al, 2013) discusses the use of Kinect with a custom build gesture recognition to interact with virtual objects in conjunction with hardware prototypes such as Arduino.<br><br></h4>
                <div class="team more"><h4 class="styledStrong text-justify" style="font-size:18px">This project draws inspiration from the above research papers to wrap a game engine behind Microsoft Kinect and explore the possibility of using this combination to enhance UX for gamers.
                        </h4></div>
                
            </div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>


    
    	<section id="Implementation" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styled">Implementation</h2><br><br><br>
				<h4 class="styledStrong text-justify">Solution Overview</h4>
				<h4 class ="styled text-justify">To design and analyze the user experience associated with interacting with Virtual Reality using natural gestures, a Google Cardboard VR game was designed and scripted in Unity3D using C Sharp. This game was then compiled against android studio SDK to create an android application which was tested on a google cardboard. The game uses interactions from Microsoft Kinect gesture recognition and transmits the data via OSC to a receiver script written in Unity. The result is such that the game can be deployed as a standalone application (no tethering required) and communicate with Microsoft Kinect via OSC in the same network. </h4> <br><br>
                <div class="col-md-6" style="padding-left:0px;"><h4 class="styledStrong text-justify">Working with Kinect</h4>
                <h4 class ="styled text-justify">To detect the Kinect skeletal data a python wrapper for Kinect V2.0 called as KinectV2OSC is used. This wrapper converts the Kinect data into OSC messages and identifies various joints and body parts with values indicating if the joint has been tracked or not. Few joints such as hands have trigger state variable whose values are either Open or Closed. The OSC message also has value indicating the confidence level of the tracking which is useful while manipulating the game object in Unity using these values. </h4></div>
                <div class="col-md-6" style="padding-right:0px; margin-top:30px;">
                <img src="img/pages/vrgame/kinect.png" width="80%" />
                </div>
                

                <div class="row"></div> <br>
                <br>
                <h4 class="styledStrong text-justify">Working with Unity3D</h4><br>
                <div class="col-md-6" style="padding-left:0px;"><img src="img/pages/vrgame/vr2.png" width="100%" /></div>
                <div class="col-md-6" style="padding-right:0px;"><h4 class ="styled text-justify">Building a VR game in Unity is different from building a conventional game in Unity. In the Conventional game a Main camera will decide the view and object positions. In VR, a stereoscopic camera is added as a replacement for the Main Camera. Google VR also provides support for Gaze detection and Gaze based input which can be used as an interaction method to interact with game objects. For this project, Gaze detection was not implemented since the interaction will be via Kinect. <br><br></h4></div>                
                                <div class="row"></div> <br>

                <h4 class="styledStrong text-justify">Communicating between Kinect and Unity</h4>
                                <h4 class ="styled text-justify">1) Transmitter: <br><br>The python Wrapper connects to the Localhost and a default port of 12345. The port and IP address can be changed using a text file containing a list of IP address and port number placed in the same folder location as that of the python Wrapper. The python wrapper upon executing opens a viewer where the skeletal data is visualized as a stick figure and the program binds itself to the assigned port and starts broadcasting the OSC data. <br><br>2) Receiver: <br><br>In order to receive OSC signals in Unity, a unity package called Rug.OSC was used. The dll and other binaries were imported in to the Unity environment and a new game object called OSC_Controller was created to monitor the trigger state of the scripts. The OSC Receive script was attached to the OSC Controller and the listening port was configured to point to the OSC broadcasting port. Once the OSC data is received in Unity, a C Sharp code was written to parse the OSC message and identify the state of the hand and make a decision out of it. For instance, If the hands are closed then a user click event is triggered on the VR game. </h4> <br><br>                
                
                
                <h4 class="styledStrong text-justify">Creating the Android Application</h4>
<h4 class ="styled text-justify">
                Unity3D version 5.0 and above has the support to create an android application from the Unity environment by building the Unity game using Android SDK tools. This results in generating android application file with the extension .apk. This file can then be moved to any android device and can be launched to interact with the VR game.
</h4> <br><br>
                
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
        	<section id="Interactions" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styled">Interactions</h2><br><br><br>
                <h4 class ="styled text-justify">It was interesting to see the Users use this application and what was also exciting to see was that user’s figured out the game play once it was instructed to the user’s that the only interaction they can use are hand gestures. After 2-3 trials, users understood all the possible interactions with the game objects and then they started playing the game more naturally and efficiently.<br><br>

It was observed during the gameplay that this interaction was tightly integrated with the application and that the interaction is very natural and engaging. Even though the interaction is made in the physical world, the event is triggered in the virtual world giving the users a mixed reality experience.
<br><br></h4>
                <h4 class="styledStrong text-justify">Result of User testing</h4><br>
                <h4 class ="styled text-justify">It was observed that the results for playing the game in Virtual Reality was more engaging and fun for the users. The experience of using a VR to play a game had little to do with the quality of game. In order to evaluate this, the prototype VR game was tested alongside other professional games. The result was that the experience remained the same across both the games. The same exercise was performed with non-vr game and it was observed that the user engagement was very less for the prototype game due to less graphics and the engagement was more for a high graphic content game.<br><br></h4>
                
                
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
    	<section id="Prototype" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styled">Prototype</h2><br><br><br>
            <h4 class ="styled text-justify">A working functional prototype of the design concept is shown below</h4>
                                <div class="video-container"><iframe src="https://player.vimeo.com/video/197983174?color=ff6161&portrait=0" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
<p class="styled text-center">VR gaming user experience design using Kinect.</p>
                </div><br><br><br>
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
    
    	<section id="Future" class="section pink-theme">
		<div class="container">
			<div class="row text-center title" ><br><br><br><br><br>
				<h2 class="styled white">Future Work</h2><br><br><br>
            <h4 class ="styled white text-justify">As with all projects and research there is always scope for improvement. This project can be further improved if the Kinect could directly talk with unity through a server-client relationship over the internet. That way, irrespective of where the Kinect is the application will be accessible across the internet. <br><br>

Further, an interesting idea to explore will be to explore two player game using VR and the interactions between both the players is governed by Kinect. It will also be interesting to see this interaction method applied to domains other than gaming.
</h4><br><br>
            <div class="box-main active" data-img="img/pricing1.jpg">
							<a href="mailto:kvmani@umich.edu?subject=Requesting VR Game Paper" class="btn styledStrong btn-white-fill">Request Full Paper</a>
						</div>    
			</div>
			</div>
            <br><br>
			

	</section>


	<footer>
		<div class="container">
			<div class="row bottom-footer text-center-mobile">
				<div class="col-sm-12 text-center">
					<p class="styled footmessage">Coded with Love <br> by <br> <p class="styledStrong white">Manikandan Kandadai Venkatesh </p></p>
				</div>
				<div class="col-sm-12 text-center text-center-mobile">
					<ul class="social-footer">
						<li><a href="https://www.linkedin.com/in/kvmani"><i class="fa fa-linkedin"></i></a></li>
						<li><a href="mailto:kvmani@umich.edu"><i class="fa fa-envelope-o"></i></a></li>
					</ul>
				</div>
			</div>
		</div>
	</footer>
	<!-- Holder for mobile navigation -->
	<div class="mobile-nav">
		<ul>
		</ul>
		<a href="#" class="close-link"><i class="arrow_up"></i></a>
	</div>
	<!-- Scripts -->
	<script src="js/jquery-1.11.1.min.js"></script>
	<script type="text/javascript">
	$(document).ready(function(){
	$('img, a[href^="#"]').on('click',function (e) {
	    e.preventDefault();

	    var target = this.hash;
	    var $target = $(target);

	    $('html, body').stop().animate({
	        'scrollTop': $target.offset().top
	    }, 700, 'swing', function () {
	        window.location.hash = target;
	    });
	});
});
</script>
	<script src="js/owl.carousel.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script src="js/wow.min.js"></script>
	<script src="js/typewriter.js"></script>
	<script src="js/jquery.onepagenav.js"></script>
	<script src="js/main.js"></script>

<script type="text/javascript">
    window._pt_lt = new Date().getTime();
    window._pt_sp_2 = [];
    _pt_sp_2.push('setAccount,6c9dab6b');
    var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    (function() {
        var atag = document.createElement('script'); atag.type = 'text/javascript'; atag.async = true;
        atag.src = _protocol + 'cjs.ptengine.com/pta_en.js';
        var stag = document.createElement('script'); stag.type = 'text/javascript'; stag.async = true;
        stag.src = _protocol + 'cjs.ptengine.com/pts.js';
        var s = document.getElementsByTagName('script')[0]; 
        s.parentNode.insertBefore(atag, s); s.parentNode.insertBefore(stag, s);
    })();
</script>
                        
</body>

</html>
