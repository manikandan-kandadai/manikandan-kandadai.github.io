<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Manikandan</title>
	<meta name="description" content="Manikandan's Portfolio" />
	<meta name="keywords" content="Portfolio, Interaction Design, Tangible Interactions, UMSI, UX Design" />
	<meta name="author" content="Manikandan K V" />
	<!-- Favicons (created with http://realfavicongenerator.net/)-->
<link rel="apple-touch-icon" sizes="57x57" href="img/favs/apple-icon-57x57.png">
<link rel="apple-touch-icon" sizes="60x60" href="img/favs/apple-icon-60x60.png">
<link rel="apple-touch-icon" sizes="72x72" href="img/favs/apple-icon-72x72.png">
<link rel="apple-touch-icon" sizes="76x76" href="img/favs/apple-icon-76x76.png">
<link rel="apple-touch-icon" sizes="114x114" href="img/favs/apple-icon-114x114.png">
<link rel="apple-touch-icon" sizes="120x120" href="img/favs/apple-icon-120x120.png">
<link rel="apple-touch-icon" sizes="144x144" href="img/favs/apple-icon-144x144.png">
<link rel="apple-touch-icon" sizes="152x152" href="img/favs/apple-icon-152x152.png">
<link rel="apple-touch-icon" sizes="180x180" href="img/favs/apple-icon-180x180.png">
<link rel="icon" type="image/png" sizes="192x192"  href="img/favs/android-icon-192x192.png">
<link rel="icon" type="image/png" sizes="32x32" href="img/favs/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="96x96" href="img/favs/favicon-96x96.png">
<link rel="icon" type="image/png" sizes="16x16" href="img/favs/favicon-16x16.png">
<link rel="manifest" href="img/favs/manifest.json">
<meta name="msapplication-TileColor" content="#ffffff">
<meta name="msapplication-TileImage" content="img/favs/ms-icon-144x144.png">
<meta name="theme-color" content="#ffffff">
	<!-- Normalize -->
	<link rel="stylesheet" type="text/css" href="css/normalize.css">
	<!-- Bootstrap -->
	<link rel="stylesheet" type="text/css" href="css/bootstrap.css">
	<!-- Owl -->
	<link rel="stylesheet" type="text/css" href="css/owl.css">
	<!-- Animate.css -->
	<link rel="stylesheet" type="text/css" href="css/animate.css">
	<!-- Font Awesome -->
	<link rel="stylesheet" type="text/css" href="fonts/font-awesome-4.1.0/css/font-awesome.min.css">
	<!-- Elegant Icons -->
	<link rel="stylesheet" type="text/css" href="fonts/eleganticons/et-icons.css">
	<!-- Main style -->
	<link rel="stylesheet" type="text/css" href="css/Main.css">
	<!-- google font -->
	<link href="https://fonts.googleapis.com/css?family=Comfortaa:300,400,700|Josefin+Sans:100,100i,300,300i,400,400i,600,600i,700,700i" rel="stylesheet">




</head>

<body>
	<div class="preloader">
		<img src="img/loader.gif" alt="Preloader image">
	</div>
	<nav class="navbar">
		<div class="container">
			<!-- Brand and toggle get grouped for better mobile display -->
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
					<span class="sr-only">Toggle</span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
				<a href="../index.html" class="navbar-brand" ><img src="img/Logo_2.svg" width="60%" data-active-url="img/Logo_2.svg" alt=""></a>
			</div>
			<!-- Collect the nav links, forms, and other content for toggling -->
			<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
				<ul class="nav navbar-nav navbar-right main-nav">
					<li><a href="#Home">Home</a></li>
                    <li><a href="#Overview">Overview</a></li>
                    <li><a href="#BResearch">Research</a></li>
					<li><a href="#Design">Design</a></li>
                    <li><a href="#Tech">Implementation</a></li>
                    <li><a href="#Interactions">Interactions</a></li>
					<li><a href="#Prototype">Prototype</a></li>
					<li><a href="#Future">Future Work</a></li>
                    <li><a href="http://manikandan-k-v.com/index.html">Back to Portfolio</a></li>
					<!-- <li><a href="#" data-toggle="modal" data-target="#modal1" class="btn btn-blue">Sign Up</a></li> -->
				</ul>
			</div>
			<!-- /.navbar-collapse -->
		</div>
		<!-- /.container-fluid -->
	</nav>
<br>
<br>
<br>
	<header id="Home">
		<div class="container tixdheader">

			<div class="table">

				<div class="header-text ">
					<div class="row">

						<div class="col-md-12 text-center">
                            <h1 class="StyledStrong">Tangible Interaction Design</h1>
                            <h4 class="typed Styled">Interaction Design • UX Design • Interactive Music Design</h4>
							<span class="typed-cursor">|</span>
						</div>

					</div>
					<br><br><br><br>
				</div>
			</div>

		</div>
	</header>
	<section id="Overview" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styledMedium">Overview</h2><br><br><br>
                <h4 class="styledStrong text-justify">About the Project:</h4>
				<h4 class ="styled text-justify">This project is aimed at improving the user experience for generating digital music on smartphones and tablets by bringing back the affordance of traditional instruments for touch devices as external modules. <br><br>As a prototype, a module of African traditional instrument "Kalimba" was designed and used to demonstrate the concept.<br><br></h4>
                <h4 class="styledStrong text-justify">Why is this important?</h4>
                <h4 class ="styled text-justify">Designing new instruments ultimately involves a change in the relationship between performed actions and perceived response. This relationship also defines the relationship between music and the audience. If there is a disconnect between the performer and the music, then there is most certainly a disconnect between the audience and the performer. The question that challenged this perception was that what if we could incorporate the best of both the worlds? The affordance of the physical instrument with the potential of digital music?</h4>
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>

    	<section id="BResearch" class="section section-padded">
		<div class="container">
			<div class="row text-center title">
				<h2 class="styledMedium">Research</h2><br><br><br>
				<h4 class ="styled text-justify">The proposed concept gets its roots from the basic categorization of the types of tangible instruments according to Essl and Sile (ESSL, G. and O’MODHRAIN, S. , 2006) <br><br>
1) One such category takes traditional instruments and augments them by adding sensing technologies. <br>
2) Instruments which replicate rather than augment traditional instruments. <br>
3) Instruments that reappropriate instrumental gestures - instruments that use the physical properties of one mechanism to control another <br>
4) Abstract tangible interfaces for music control which have no parallels in existing instrument design<br><br>
                The second category of digital tangible instrument is the source of inspiration for the project. This kind of instrument category tends to recreate the parts of the instrument as a part of the interaction rather than replacing the instrument.<br><br>
                    <blockquote class="styledStrong"style="font-size:18px">For example, the vBow (Nicols 2003) is a replication of the bowed string, but the string is replaced with a force-feedback mechanism, so that the physical interface has been decoupled from the sounding of a physical string. The biggest drawback with vBow is the physical decoupling that is obvious to the performer and the audience.</blockquote>
                <br><br>Few professional digital instruments have tried to replicate the affordance of its traditional counterparts and have been very sucessful. For instance, the Roli SeaBoard keyboard controller looks very similar to a piano keyboard and costs about 2000 USD. This is however a professional device and hence the price. But what’s interesting here is that to create digital music with an instrument that provides the same affordance as its traditional counterpart one must heavily invest on the instrument. This is obviously not for beginners or hobbyist. This growing gap has been unaddressed for many years now.<br><br></h4>
                    <div class="team more"><h4 class="styledStrong text-justify" style="font-size:18px">This project concentrates on bridging the gap by creating low cost modular instruments that augment the affordance of traditional instruments and can be attached to smartphones to directly manipulate digital music using existing smartphone applications.
                        <br><br></h4></div>
               
            </div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
    
    
	<section id="Design" class="section section-padded">
		<div class="container">
			<div class="row text-center title">
				<h2 class="styledMedium">Design</h2><br><br><br>
                <h4 class="styledStrong text-left">Proposed Solution</h4>
				<h4 class ="styled text-justify">This design concept is a prototype designed around using bamboo sticks and the notes generated by plucking the sticks is processed by offloading it to a personal computer running a python script. <br><br>One key element to this solution was to recreate the affordance of the musical instrument. As a prototype the traditional African thumb piano also called the “Kalimba” was prototyped using plywood and bamboo sticks.<br><br></h4>
                <div class="col-md-6" style="padding-left:0px;"><h4 class="styledStrong text-left">Aesthetic Design</h4>
                <h4 class="styled text-justify">The prototype design is illustrated in the Figure and the design is made to be ergonomic and portable and fits around a smartphone and the smartphone can slide into a sleeve which is present under the module. <br><br>The design contains two long wooden handles which acts as the grip for the user to hold and play the instrument. The tines (bamboo sticks) are placed in a semi-circular array and is accessible by the thumb from both the handles. This design is similar in appearance to that of a traditional Kalimba and the affordance of the instrument makes it easy for any user to use the instrument. </h4></div>
                <br>
                <div class="col-md-6" style="padding-right:0px;"><img src="img/pages/tixd/design.png" width="100%"  /></div>
                <br>
                <div class="row"></div><br>
                
                <div class="col-md-6" style="padding-left:0px;"><h4 class="styledStrong text-justify">Design for Affordance</h4>
                <h4 class="styled text-justify">The Prototype is carefully designed to make sure that the design expresses the expected affordance to a user. As can be seen from Figure, the various parts of the prototype self-explain its functions. For instance, the two handles insist that the device needs to be held using both the hands and the hands need to be rested on the handle bars. The bamboo tines invite the user to play by plucking them. The smartphone sleeve makes it easy for the user to slip in the smartphone and place it in a comfortable position so that the microphone has access to the harmonics produced by the tines. <br><br>The overall design works seamlessly in letting the users know about the various functions each segment of the design performs. This is in stark difference to the other digital instruments in the market which requires some learning and getting used to. </h4></div>
                
                <div class="col-md-6" style="padding-right:0px;"><img src="img/pages/tixd/cover.png" width="100%" /></div>
            <br></div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>

    	<section id="Tech" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styledMedium">Implementation</h2><br><br><br>
                <h4 class="styledStrong text-justify">Setup</h4>
				<h4 class ="styled text-justify">The setup consists of 3 major parts as described in the Figure. The instrument module, A smart phone and a personal computer to process the signals. <br><br>1) The smartphone attached to the instrument module streams the audio signals over Wi-Fi to the python client running in the personal computer. <br>2) The python client running keeps listening to the audio stream continuously and samples the signals at the rate of 44,100 or 48,000.<br>3) These chunks are constantly monitored by comparing the root mean square value of the signal to a threshold value determined by the ambient noise. <br>4) The signal strength when crosses the threshold triggers a function that starts recording the sound for 2-3 seconds. <br>5) This file is immediately processed using Fast Fourier Transform to identify the frequency.<br>6) This is then used to start separate threads of MIDI notes that corresponds to the generated frequency.<br><br> For the prototype, the original notes of a traditional kalimba is used to recreate the experience of playing a real kalimba.<br><br><br></h4>
                    <img src="img/pages/tixd/Flow_diag.png" width="80%"/><br><br><br>
<h4 class ="styled text-justify">The user can also add reverb and other effects to the music using the gyroscope inbuilt in the smartphone. An independent mobile application such as AndOSC or TouchOSC can stream the Gyro and other sensor values as OSC signals over the WIFI to a computer. The gyro values are then captured using a library in python called the PyOSC. These values are used to control the reverb and other audio effects by changing the value of decay, feedback and other parameters that determines the effect being created.<br><br></h4>
                
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
    
    	<section id="Interactions" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styledMedium">Interaction</h2><br><br><br>
				<h4 class="styledStrong text-justify">Interactions</h4>
				<h4 class ="styled text-justify">The interaction is straightforward with the instrument. The user must hold the device using both handles and pluck the tines to create digital music. While doing so the user can move the device up and down or shake it in a rhythmic pattern to generate musical effects on the generated music. This effect can be controlled by how fast and by what angle the device is translated from its initial position. The instrument is not tethered to the device and hence the user is not constrained by any physical movements with regards to his orientation in space while interacting with the device. The only constraint would be the affordance of the instrument itself which as per Lian (Lian Loke and Toni Robertson. 2008) is the best way to create and device methods of interaction and experience.</h4> <br><br>
                
                <h4 class="styledStrong text-justify">User Experience</h4>
                <h4 class ="styled text-justify">The user experience of using a device that’s so close to the traditional instrument makes it enjoyable for music enthusiasts and beginners alike. The experience of using a traditional instrument with digital music is likely to make “traditional music likers” try out digital mixes and audio synthesis given that the user experience by using this instrument module is very similar to the real experience of using a traditional instrument.</h4> <br><br>
                
                
                
			</div>
			
		</div>
		<div class="cut cut-bottom"></div>
	</section>
    
    	<section id="Prototype" class="section section-padded">
		<div class="container">
			<div class="row text-center title" >
				<h2 class="styledMedium">Prototype</h2><br><br><br>
            <h4 class="styledStrong text-justify">Prototype</h4>
            <h4 class ="styled text-justify">The video demonstration of the concept is linked below</h4>
			</div>
			<div class="video-container"><iframe src="https://player.vimeo.com/video/196041847?color=ff6161&portrait=0" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe> <p>Use of instruments as individual modules with smartphone to generate music. <br /> <br /> Technology used: Python (audio processing), Android OSC App ( to capture Audio)</p></div>
		</div>
		<div class="cut cut-bottom"></div><br><br><br>
	</section>
    
    	<section id="Future" class="section pink-theme">
		<div class="container">
			<div class="row text-center title" ><br><br><br><br><br>
				<h2 class="styledMedium white" style="color:white;">Future Work</h2><br><br><br>
            <h4 class ="styled white text-justify">As far as the future goal of this project is concerned, there are two apparent modifications to be made to the design and working of the prototype. Firstly, the prototype needs to be made smaller and needs to be build using real instrument grade materials. Second, the processing can be offloaded from remote machine to an app that can run on any smartphone. This transforms the way users use the device by creating, synthesizing and mixing music using instruments on top of the smartphone. The fact that these can run on smartphones opens an entire spectrum of the user’s ability to share the music to other applications, and store files on the cloud.</h4><br><br>
            <div class="box-main active" data-img="img/pricing1.jpg">
							<a href="mailto:mani92kv@gmail.com?subject=Requesting Modular Instruments Paper" class="btn styledStrong btn-white-fill">Request Full Paper</a>
						</div>    
			</div>
			</div>
            <br><br>
			

	</section>



	<footer>
		<div class="container">

			<div class="row bottom-footer text-center-mobile">
				<div class="col-sm-12 text-center">
					<p class="styled footmessage"><p class="styledStrong white">Manikandan Kandadai Venkatesh </p></p>
				</div>
				<div class="col-sm-12 text-center text-center-mobile">
					<ul class="social-footer">
						<li><a href="https://www.linkedin.com/in/kvmani"><i class="fa fa-linkedin"></i></a></li>
						<li><a href="mailto:mani92kv@gmail.com"><i class="fa fa-envelope-o"></i></a></li>
					</ul>
				</div>
			</div>
		</div>
	</footer>
	<!-- Holder for mobile navigation -->
	<div class="mobile-nav">
		<ul>
		</ul>
		<a href="#" class="close-link"><i class="arrow_up"></i></a>
	</div>
	<!-- Scripts -->
	<script src="js/jquery-1.11.1.min.js"></script>
	<script type="text/javascript">
	$(document).ready(function(){
	$('img, a[href^="#"]').on('click',function (e) {
	    e.preventDefault();

	    var target = this.hash;
	    var $target = $(target);

	    $('html, body').stop().animate({
	        'scrollTop': $target.offset().top
	    }, 700, 'swing', function () {
	        window.location.hash = target;
	    });
	});
});
</script>
	<script src="js/owl.carousel.min.js"></script>
	<script src="js/bootstrap.min.js"></script>
	<script src="js/wow.min.js"></script>
	<script src="js/typewriter.js"></script>
	<script src="js/jquery.onepagenav.js"></script>
	<script src="js/main.js"></script>

<script type="text/javascript">
    window._pt_lt = new Date().getTime();
    window._pt_sp_2 = [];
    _pt_sp_2.push('setAccount,6c9dab6b');
    var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    (function() {
        var atag = document.createElement('script'); atag.type = 'text/javascript'; atag.async = true;
        atag.src = _protocol + 'cjs.ptengine.com/pta_en.js';
        var stag = document.createElement('script'); stag.type = 'text/javascript'; stag.async = true;
        stag.src = _protocol + 'cjs.ptengine.com/pts.js';
        var s = document.getElementsByTagName('script')[0]; 
        s.parentNode.insertBefore(atag, s); s.parentNode.insertBefore(stag, s);
    })();
</script>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90113013-1', 'auto');
  ga('send', 'pageview');

</script>
                        
</body>

</html>
